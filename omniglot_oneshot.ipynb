{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "omniglot_oneshot.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinavj98/machine-learning/blob/master/omniglot_oneshot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "RD5uFPybUj-s",
        "colab_type": "code",
        "outputId": "fe8013d0-fec8-488a-e15f-39ff6e066c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/brendenlake/omniglot.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'omniglot'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 81 (delta 0), reused 0 (delta 0), pack-reused 78\u001b[K\n",
            "Unpacking objects: 100% (81/81), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PpZBpzi1UlxH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cnz6xVcaUxF5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip /content/omniglot/python/images_evaluation.zip\n",
        "!unzip /content/omniglot/python/images_background.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JmRMQy0fVQrD",
        "colab_type": "code",
        "outputId": "893ee9b4-bc95-4506-db42-c5c8d9130b95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "images_background  images_evaluation  omniglot\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WqDdHgl-XV3S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "from keras.engine.topology import Layer\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Rk-JEXTVlhR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_dataset(path):\n",
        "    \"\"\"Load dataset by path, returns Data values, labels and dict containg name of lang and its characters\"\"\"\n",
        "    X=[]\n",
        "    y = []\n",
        "    cat = {}\n",
        "    lang = {}\n",
        "    curr_y = 0\n",
        "    \n",
        "    for alphabet in os.listdir(path):\n",
        "        print(\"loading alphabet: \" + alphabet)\n",
        "        lang[alphabet] = [0,None]\n",
        "        alphabet_path = os.path.join(path,alphabet)\n",
        "        \n",
        "        for numletter, letter in enumerate(os.listdir(alphabet_path)):\n",
        "          cat[numletter] = (alphabet, letter)\n",
        "          category_images=[]\n",
        "          letter_path = os.path.join(alphabet_path, letter)\n",
        "        \n",
        "          for filename in os.listdir(letter_path):\n",
        "            image_path = os.path.join(letter_path, filename)\n",
        "            image = imread(image_path)\n",
        "            category_images.append(image)\n",
        "            y.append(numletter)\n",
        "          \n",
        "          X.append(np.stack(category_images))\n",
        "          lang[alphabet][1] = numletter - 1\n",
        "    y = np.vstack(y)\n",
        "    X = np.stack(X)\n",
        "    return X,y,lang"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cTBH4tO8XAsw",
        "colab_type": "code",
        "outputId": "5b93c5cb-8d79-496c-ba0c-b3715c86bb15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "cell_type": "code",
      "source": [
        "train_path = '/content/images_background'\n",
        "test_path = '/content/images_evaluation'\n",
        "X_train,Y_train,lang_train = load_dataset(train_path)\n",
        "X_test,Y_test,lang_test = load_dataset(test_path)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading alphabet: Burmese_(Myanmar)\n",
            "loading alphabet: Tifinagh\n",
            "loading alphabet: Latin\n",
            "loading alphabet: Inuktitut_(Canadian_Aboriginal_Syllabics)\n",
            "loading alphabet: Korean\n",
            "loading alphabet: Tagalog\n",
            "loading alphabet: Braille\n",
            "loading alphabet: Greek\n",
            "loading alphabet: Alphabet_of_the_Magi\n",
            "loading alphabet: Early_Aramaic\n",
            "loading alphabet: Japanese_(katakana)\n",
            "loading alphabet: Grantha\n",
            "loading alphabet: Cyrillic\n",
            "loading alphabet: Sanskrit\n",
            "loading alphabet: Mkhedruli_(Georgian)\n",
            "loading alphabet: Japanese_(hiragana)\n",
            "loading alphabet: Ojibwe_(Canadian_Aboriginal_Syllabics)\n",
            "loading alphabet: Armenian\n",
            "loading alphabet: Arcadian\n",
            "loading alphabet: Futurama\n",
            "loading alphabet: Anglo-Saxon_Futhorc\n",
            "loading alphabet: Gujarati\n",
            "loading alphabet: N_Ko\n",
            "loading alphabet: Balinese\n",
            "loading alphabet: Asomtavruli_(Georgian)\n",
            "loading alphabet: Hebrew\n",
            "loading alphabet: Syriac_(Estrangelo)\n",
            "loading alphabet: Malay_(Jawi_-_Arabic)\n",
            "loading alphabet: Blackfoot_(Canadian_Aboriginal_Syllabics)\n",
            "loading alphabet: Bengali\n",
            "loading alphabet: Oriya\n",
            "loading alphabet: Keble\n",
            "loading alphabet: Glagolitic\n",
            "loading alphabet: Tibetan\n",
            "loading alphabet: Manipuri\n",
            "loading alphabet: Atemayar_Qelisayer\n",
            "loading alphabet: Mongolian\n",
            "loading alphabet: Atlantean\n",
            "loading alphabet: Syriac_(Serto)\n",
            "loading alphabet: Tengwar\n",
            "loading alphabet: ULOG\n",
            "loading alphabet: Sylheti\n",
            "loading alphabet: Avesta\n",
            "loading alphabet: Angelic\n",
            "loading alphabet: Kannada\n",
            "loading alphabet: Malayalam\n",
            "loading alphabet: Aurek-Besh\n",
            "loading alphabet: Old_Church_Slavonic_(Cyrillic)\n",
            "loading alphabet: Gurmukhi\n",
            "loading alphabet: Ge_ez\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vztgkIxZXTgv",
        "colab_type": "code",
        "outputId": "4d202b04-f9f2-4527-c052-668bfab5d697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(str(X_train.shape) + \"   \" + str(len(lang_train.keys())))\n",
        "print(str(X_test.shape) + \"   \" + str(len(lang_test.keys())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(964, 20, 105, 105)   30\n",
            "(659, 20, 105, 105)   20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vkxBFJKEnR1h",
        "colab_type": "code",
        "outputId": "b3c53f62-9a45-4bee-ecf3-360184b52f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  temp = np.random.randint(0, X_train.shape[0])\n",
        "  temp2 = np.random.randint(0, X_train.shape[1])\n",
        "  plt.subplot(2,5,i+1)\n",
        "  plt.imshow(X_train[temp,temp2,:,:], cmap = 'gray')\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAETCAYAAAASx/7oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngFOUNAAATv0/qhcrn5uK2dMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "jVQSW52meIJs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_batch(batch_size,s=\"train\"):\n",
        "    \"\"\"\n",
        "    Create batch of n pairs, half same class, half different class\n",
        "    \"\"\"\n",
        "    if s == 'train':\n",
        "        X = X_train\n",
        "    else:\n",
        "        X = X_test\n",
        "    n_classes, n_examples, w, h = X.shape\n",
        "    \n",
        "    # randomly sample several classes to use in the batch\n",
        "    categories = np.random.choice(n_classes,size=(batch_size,1),replace=False)\n",
        "    pairs=[np.zeros((batch_size, h, w,1)) for i in range(2)]\n",
        "    targets=np.zeros((batch_size,1))\n",
        "    targets[batch_size//2:] = 1\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "      category = categories[i]\n",
        "      index1 = np.random.randint(0, n_examples)\n",
        "      pairs[0][i,:,:,:] = X[category, index1].reshape(w, h, 1)\n",
        "      index2 = np.random.randint(0, n_examples)\n",
        "      if i >= batch_size // 2:\n",
        "        category2 = category  \n",
        "      else: \n",
        "        category2 = (category + np.random.randint(1,n_classes)) % n_classes\n",
        "        \n",
        "      pairs[1][i,:,:,:] = X[category2,index2].reshape(w, h,1)\n",
        "    \n",
        "    return pairs, targets\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H2rqzqDoiaFY",
        "colab_type": "code",
        "outputId": "fd61b6cc-7ed4-45ee-b5da-825ec9b533ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "a,b = get_batch(54)\n",
        "print(a[0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54, 105, 105, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HIRyOgVrj2Hc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate(batch_size, s=\"train\"):\n",
        "    \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
        "    while True:\n",
        "        pairs, targets = get_batch(batch_size,s)\n",
        "        yield (pairs, targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kuYevTcIk3xW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_weights(shape, name=None):\n",
        "    \"\"\"\n",
        "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
        "    \"\"\"\n",
        "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y9cMlcdmqVj1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_bias(shape, name=None):\n",
        "    \"\"\"\n",
        "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
        "    \"\"\"\n",
        "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2-b1evDTqXvd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_siamese_model(input_shape):\n",
        "    \"\"\"\n",
        "        Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the tensors for the two input images\n",
        "    left_input = Input(input_shape)\n",
        "    right_input = Input(input_shape)\n",
        "    \n",
        "    # Convolutional Neural Network\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
        "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(128, (7,7), activation='relu',\n",
        "                     kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='sigmoid',\n",
        "                   kernel_regularizer=l2(1e-3),\n",
        "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
        "    \n",
        "    # Generate the encodings (feature vectors) for the two images\n",
        "    encoded_l = model(left_input)\n",
        "    encoded_r = model(right_input)\n",
        "    \n",
        "    # Add a customized layer to compute the absolute difference between the encodings\n",
        "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
        "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
        "    \n",
        "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
        "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(L1_distance)\n",
        "    \n",
        "    # Connect the inputs with the outputs\n",
        "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
        "    \n",
        "    # return the model\n",
        "    return siamese_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uypD1ehLqbDx",
        "colab_type": "code",
        "outputId": "f62e9e0d-8450-4040-975b-a22faaa74580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "model = get_siamese_model((105, 105, 1))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 105, 105, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            (None, 105, 105, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_4 (Sequential)       (None, 4096)         38947648    input_7[0][0]                    \n",
            "                                                                 input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 4096)         0           sequential_4[1][0]               \n",
            "                                                                 sequential_4[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 1)            4097        lambda_4[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 38,951,745\n",
            "Trainable params: 38,951,745\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1tL8dvHWqcvo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = Adam(lr = 0.00006)\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_HSu7pVFrQvb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_oneshot_task(N):\n",
        "    X = X_test\n",
        "    n_classes, n_examples, w, h = X.shape\n",
        "    \n",
        "    indices = np.random.randint(0, n_examples,size=(N,))\n",
        "    categories = np.random.choice(range(n_classes),size=(N,),replace=False)            \n",
        "    true_category = categories[0]\n",
        "    ex1, ex2 = np.random.choice(n_examples,replace=False,size=(2,))\n",
        "    test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N, w, h,1)\n",
        "    support_set = X[categories,indices,:,:]\n",
        "    support_set[0,:,:] = X[true_category,ex2]\n",
        "    support_set = support_set.reshape(N, w, h,1)\n",
        "    targets = np.zeros((N,))\n",
        "    targets[0] = 1\n",
        "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
        "    pairs = [test_image,support_set]\n",
        "\n",
        "    return pairs, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uafcDw1Ixaji",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_oneshot(model, N, k, s = \"val\", verbose = 0):\n",
        "    \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
        "    n_correct = 0\n",
        "    if verbose:\n",
        "        print(\"Evaluating model on {} random {} way one-shot learning tasks ... \\n\".format(k,N))\n",
        "    for i in range(k):\n",
        "        inputs, targets = make_oneshot_task(N,s)\n",
        "        probs = model.predict(inputs)\n",
        "        if np.argmax(probs) == np.argmax(targets):\n",
        "            n_correct+=1\n",
        "    percent_correct = (100.0 * n_correct / k)\n",
        "    if verbose:\n",
        "        print(\"Got an average of {}% {} way one-shot learning accuracy \\n\".format(percent_correct,N))\n",
        "    return percent_correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eU8G1W91xwNG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyper parameters\n",
        "evaluate_every = 100\n",
        "batch_size = 32\n",
        "n_iter = 20000\n",
        "N_way = 20 \n",
        "n_val = 250\n",
        "best = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6w58644ux0ul",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_path = '/content/weights/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xQkxps9Lx7YV",
        "colab_type": "code",
        "outputId": "26794ac3-4f7c-4673-94f3-f3ac9408f9ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 30651
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Starting training process!\")\n",
        "print(\"-------------------------------------\")\n",
        "t_start = time.time()\n",
        "for i in range(1, n_iter+1):\n",
        "    (inputs,targets) = get_batch(batch_size)\n",
        "    loss = model.train_on_batch(inputs, targets)\n",
        "    if i % evaluate_every == 0:\n",
        "        print(\"\\n ------------- \\n\")\n",
        "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
        "        print(\"Train Loss: {0}\".format(loss)) \n",
        "        val_acc = test_oneshot(model, N_way, n_val, verbose=True)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training process!\n",
            "-------------------------------------\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 100 iterations: 0.303971449534 mins\n",
            "Train Loss: 1.25865709782\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 54.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 200 iterations: 0.759896600246 mins\n",
            "Train Loss: 1.20657384396\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 50.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 300 iterations: 1.21734739939 mins\n",
            "Train Loss: 1.21267402172\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 54.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 400 iterations: 1.67654774984 mins\n",
            "Train Loss: 1.01059710979\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 50.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 500 iterations: 2.1363180836 mins\n",
            "Train Loss: 0.940947890282\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 62.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 600 iterations: 2.59585241874 mins\n",
            "Train Loss: 0.982377409935\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 62.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 700 iterations: 3.05608994961 mins\n",
            "Train Loss: 1.00705051422\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 60.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 800 iterations: 3.51505693197 mins\n",
            "Train Loss: 0.845731496811\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 64.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 900 iterations: 3.97246908347 mins\n",
            "Train Loss: 0.853678703308\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 58.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1000 iterations: 4.43256816864 mins\n",
            "Train Loss: 0.751236319542\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 59.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1100 iterations: 4.89537883202 mins\n",
            "Train Loss: 0.763919770718\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 56.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1200 iterations: 5.35765004953 mins\n",
            "Train Loss: 0.797922730446\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 59.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1300 iterations: 5.81980415185 mins\n",
            "Train Loss: 0.652396559715\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 62.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1400 iterations: 6.28082176844 mins\n",
            "Train Loss: 0.578302502632\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1500 iterations: 6.73678135077 mins\n",
            "Train Loss: 0.630035758018\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 68.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1600 iterations: 7.19199906588 mins\n",
            "Train Loss: 0.669091463089\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 64.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1700 iterations: 7.64715801875 mins\n",
            "Train Loss: 0.685234308243\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 64.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1800 iterations: 8.10223018328 mins\n",
            "Train Loss: 0.500610470772\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 66.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1900 iterations: 8.55881358385 mins\n",
            "Train Loss: 0.468409746885\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2000 iterations: 9.01712136666 mins\n",
            "Train Loss: 0.683556079865\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2100 iterations: 9.47538143396 mins\n",
            "Train Loss: 0.444694757462\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 66.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2200 iterations: 9.9345998168 mins\n",
            "Train Loss: 0.83402132988\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2300 iterations: 10.3935111682 mins\n",
            "Train Loss: 0.460551172495\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2400 iterations: 10.8516348998 mins\n",
            "Train Loss: 0.417792856693\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 71.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2500 iterations: 11.3099738518 mins\n",
            "Train Loss: 0.409911572933\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 64.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2600 iterations: 11.7698597153 mins\n",
            "Train Loss: 0.413503170013\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2700 iterations: 12.2327900489 mins\n",
            "Train Loss: 0.36274343729\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2800 iterations: 12.6924896161 mins\n",
            "Train Loss: 0.361042529345\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 68.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2900 iterations: 13.152516516 mins\n",
            "Train Loss: 0.363812595606\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 69.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3000 iterations: 13.6124462008 mins\n",
            "Train Loss: 0.447522044182\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3100 iterations: 14.0722145518 mins\n",
            "Train Loss: 0.450712561607\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3200 iterations: 14.5315270344 mins\n",
            "Train Loss: 0.351443052292\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3300 iterations: 14.9890994827 mins\n",
            "Train Loss: 0.405103236437\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3400 iterations: 15.445110933 mins\n",
            "Train Loss: 0.409224182367\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 66.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3500 iterations: 15.9010177175 mins\n",
            "Train Loss: 0.304567754269\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3600 iterations: 16.3576995015 mins\n",
            "Train Loss: 0.402805745602\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3700 iterations: 16.8146479328 mins\n",
            "Train Loss: 0.454270243645\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 68.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3800 iterations: 17.2712001324 mins\n",
            "Train Loss: 0.423453688622\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 65.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3900 iterations: 17.7311144352 mins\n",
            "Train Loss: 0.323877573013\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 69.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4000 iterations: 18.1905254682 mins\n",
            "Train Loss: 0.270892322063\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4100 iterations: 18.6504559517 mins\n",
            "Train Loss: 0.368042886257\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 68.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4200 iterations: 19.1105140845 mins\n",
            "Train Loss: 0.336439281702\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4300 iterations: 19.5692412178 mins\n",
            "Train Loss: 0.444611847401\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4400 iterations: 20.0303155661 mins\n",
            "Train Loss: 0.317236214876\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 66.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4500 iterations: 20.493147552 mins\n",
            "Train Loss: 0.359189301729\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4600 iterations: 20.9555664857 mins\n",
            "Train Loss: 0.485586762428\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4700 iterations: 21.4182588021 mins\n",
            "Train Loss: 0.433619856834\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4800 iterations: 21.8831655661 mins\n",
            "Train Loss: 0.418600320816\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4900 iterations: 22.3463678161 mins\n",
            "Train Loss: 0.233022540808\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5000 iterations: 22.8090274493 mins\n",
            "Train Loss: 0.234471097589\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 71.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5100 iterations: 23.2691789667 mins\n",
            "Train Loss: 0.459949970245\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 71.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5200 iterations: 23.7263420661 mins\n",
            "Train Loss: 0.239299058914\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5300 iterations: 24.1850832343 mins\n",
            "Train Loss: 0.283577799797\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5400 iterations: 24.6411987662 mins\n",
            "Train Loss: 0.314771294594\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5500 iterations: 25.0979217847 mins\n",
            "Train Loss: 0.41564655304\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 67.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5600 iterations: 25.5573238492 mins\n",
            "Train Loss: 0.219928666949\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5700 iterations: 26.0166668177 mins\n",
            "Train Loss: 0.262705802917\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5800 iterations: 26.4760715683 mins\n",
            "Train Loss: 0.261520773172\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5900 iterations: 26.9359003504 mins\n",
            "Train Loss: 0.27848482132\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6000 iterations: 27.3957740188 mins\n",
            "Train Loss: 0.215258181095\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6100 iterations: 27.855869019 mins\n",
            "Train Loss: 0.249565541744\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6200 iterations: 28.3151474516 mins\n",
            "Train Loss: 0.247777044773\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6300 iterations: 28.7720621506 mins\n",
            "Train Loss: 0.234969317913\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6400 iterations: 29.2280265689 mins\n",
            "Train Loss: 0.236391782761\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6500 iterations: 29.6851922353 mins\n",
            "Train Loss: 0.368658483028\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6600 iterations: 30.144584616 mins\n",
            "Train Loss: 0.451601982117\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6700 iterations: 30.6048676332 mins\n",
            "Train Loss: 0.247645914555\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6800 iterations: 31.0645605326 mins\n",
            "Train Loss: 0.239056959748\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6900 iterations: 31.5236592174 mins\n",
            "Train Loss: 0.215660735965\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7000 iterations: 31.9832207839 mins\n",
            "Train Loss: 0.409159719944\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7100 iterations: 32.4431033492 mins\n",
            "Train Loss: 0.249291539192\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7200 iterations: 32.9026479681 mins\n",
            "Train Loss: 0.348297059536\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7300 iterations: 33.3619642178 mins\n",
            "Train Loss: 0.31403362751\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7400 iterations: 33.8210262338 mins\n",
            "Train Loss: 0.220110148191\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7500 iterations: 34.2803127845 mins\n",
            "Train Loss: 0.235493123531\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7600 iterations: 34.7395833492 mins\n",
            "Train Loss: 0.333052992821\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7700 iterations: 35.1990904013 mins\n",
            "Train Loss: 0.188972279429\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7800 iterations: 35.6584338824 mins\n",
            "Train Loss: 0.228293389082\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7900 iterations: 36.117884632 mins\n",
            "Train Loss: 0.194025054574\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8000 iterations: 36.5766301155 mins\n",
            "Train Loss: 0.213802844286\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8100 iterations: 37.0358072003 mins\n",
            "Train Loss: 0.188621759415\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8200 iterations: 37.4949172179 mins\n",
            "Train Loss: 0.195112973452\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8300 iterations: 37.9540960511 mins\n",
            "Train Loss: 0.189008146524\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8400 iterations: 38.4134443521 mins\n",
            "Train Loss: 0.208851307631\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8500 iterations: 38.8714014848 mins\n",
            "Train Loss: 0.226086109877\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8600 iterations: 39.3277096987 mins\n",
            "Train Loss: 0.256647348404\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8700 iterations: 39.7827824672 mins\n",
            "Train Loss: 0.201398178935\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8800 iterations: 40.2396589518 mins\n",
            "Train Loss: 0.204799264669\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 68.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8900 iterations: 40.7006591161 mins\n",
            "Train Loss: 0.205751091242\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9000 iterations: 41.1647732337 mins\n",
            "Train Loss: 0.299374818802\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9100 iterations: 41.6290841182 mins\n",
            "Train Loss: 0.211706966162\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9200 iterations: 42.0975443999 mins\n",
            "Train Loss: 0.220318183303\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9300 iterations: 42.5659055511 mins\n",
            "Train Loss: 0.249530375004\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9400 iterations: 43.0336482008 mins\n",
            "Train Loss: 0.231139272451\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9500 iterations: 43.4989437183 mins\n",
            "Train Loss: 0.23454888165\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9600 iterations: 43.966295282 mins\n",
            "Train Loss: 0.167541474104\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9700 iterations: 44.4332274 mins\n",
            "Train Loss: 0.169380664825\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9800 iterations: 44.8996136189 mins\n",
            "Train Loss: 0.159652203321\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9900 iterations: 45.3668626825 mins\n",
            "Train Loss: 0.212742462754\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10000 iterations: 45.8338382681 mins\n",
            "Train Loss: 0.206103622913\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10100 iterations: 46.3014557838 mins\n",
            "Train Loss: 0.232562422752\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10200 iterations: 46.7686511 mins\n",
            "Train Loss: 0.236944496632\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10300 iterations: 47.235956951 mins\n",
            "Train Loss: 0.191563114524\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 85.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10400 iterations: 47.7044007858 mins\n",
            "Train Loss: 0.175227642059\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10500 iterations: 48.1724132021 mins\n",
            "Train Loss: 0.18160225451\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10600 iterations: 48.6400264819 mins\n",
            "Train Loss: 0.172579556704\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10700 iterations: 49.1082292835 mins\n",
            "Train Loss: 0.265420347452\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10800 iterations: 49.5757263025 mins\n",
            "Train Loss: 0.40604609251\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10900 iterations: 50.0426819324 mins\n",
            "Train Loss: 0.170817151666\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11000 iterations: 50.5100951831 mins\n",
            "Train Loss: 0.20981323719\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11100 iterations: 50.9785302162 mins\n",
            "Train Loss: 0.17852050066\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11200 iterations: 51.4466663321 mins\n",
            "Train Loss: 0.19714358449\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11300 iterations: 51.9150099834 mins\n",
            "Train Loss: 0.182060778141\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11400 iterations: 52.3833773653 mins\n",
            "Train Loss: 0.280131042004\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11500 iterations: 52.8507632017 mins\n",
            "Train Loss: 0.482094228268\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11600 iterations: 53.3179109176 mins\n",
            "Train Loss: 0.205132305622\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11700 iterations: 53.7824004332 mins\n",
            "Train Loss: 0.255852222443\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11800 iterations: 54.2466015339 mins\n",
            "Train Loss: 0.196397662163\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11900 iterations: 54.7106071353 mins\n",
            "Train Loss: 0.24295014143\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12000 iterations: 55.1743657827 mins\n",
            "Train Loss: 0.174990788102\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12100 iterations: 55.6378503005 mins\n",
            "Train Loss: 0.271424382925\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12200 iterations: 56.1020773331 mins\n",
            "Train Loss: 0.16798274219\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12300 iterations: 56.5661954323 mins\n",
            "Train Loss: 0.243850409985\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12400 iterations: 57.0303287347 mins\n",
            "Train Loss: 0.158010169864\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12500 iterations: 57.4929928819 mins\n",
            "Train Loss: 0.198968589306\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12600 iterations: 57.9563490987 mins\n",
            "Train Loss: 0.253191739321\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12700 iterations: 58.4197833498 mins\n",
            "Train Loss: 0.186212539673\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12800 iterations: 58.8833291491 mins\n",
            "Train Loss: 0.152139171958\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12900 iterations: 59.3462754687 mins\n",
            "Train Loss: 0.169987738132\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13000 iterations: 59.8097796003 mins\n",
            "Train Loss: 0.182017683983\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13100 iterations: 60.2716537674 mins\n",
            "Train Loss: 0.184385925531\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13200 iterations: 60.7310513179 mins\n",
            "Train Loss: 0.141105115414\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13300 iterations: 61.1894460678 mins\n",
            "Train Loss: 0.326291620731\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13400 iterations: 61.648484532 mins\n",
            "Train Loss: 0.227337822318\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13500 iterations: 62.10671465 mins\n",
            "Train Loss: 0.169540569186\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13600 iterations: 62.5651115855 mins\n",
            "Train Loss: 0.183415800333\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13700 iterations: 63.0241749684 mins\n",
            "Train Loss: 0.14824745059\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13800 iterations: 63.4826444348 mins\n",
            "Train Loss: 0.171038389206\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13900 iterations: 63.9406479677 mins\n",
            "Train Loss: 0.246558666229\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14000 iterations: 64.399229451 mins\n",
            "Train Loss: 0.249827235937\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14100 iterations: 64.8608430823 mins\n",
            "Train Loss: 0.222704514861\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14200 iterations: 65.3221512357 mins\n",
            "Train Loss: 0.199078053236\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14300 iterations: 65.7835061669 mins\n",
            "Train Loss: 0.167707100511\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14400 iterations: 66.2457617839 mins\n",
            "Train Loss: 0.20420384407\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14500 iterations: 66.7073130687 mins\n",
            "Train Loss: 0.139268606901\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14600 iterations: 67.1689018687 mins\n",
            "Train Loss: 0.166195243597\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14700 iterations: 67.6299330831 mins\n",
            "Train Loss: 0.209869384766\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14800 iterations: 68.0919944008 mins\n",
            "Train Loss: 0.149764120579\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14900 iterations: 68.5536800345 mins\n",
            "Train Loss: 0.178050994873\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15000 iterations: 69.0150738994 mins\n",
            "Train Loss: 0.231861367822\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15100 iterations: 69.4763921857 mins\n",
            "Train Loss: 0.300340652466\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15200 iterations: 69.9377921661 mins\n",
            "Train Loss: 0.181784629822\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15300 iterations: 70.3987606168 mins\n",
            "Train Loss: 0.429244697094\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15400 iterations: 70.860080119 mins\n",
            "Train Loss: 0.17358392477\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15500 iterations: 71.3219163338 mins\n",
            "Train Loss: 0.17130702734\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15600 iterations: 71.7834923506 mins\n",
            "Train Loss: 0.14306601882\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15700 iterations: 72.2448242823 mins\n",
            "Train Loss: 0.283988445997\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15800 iterations: 72.7060629169 mins\n",
            "Train Loss: 0.165118128061\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15900 iterations: 73.1671242356 mins\n",
            "Train Loss: 0.1475712955\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16000 iterations: 73.6290149013 mins\n",
            "Train Loss: 0.185902535915\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16100 iterations: 74.090600117 mins\n",
            "Train Loss: 0.177422612906\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16200 iterations: 74.5522770683 mins\n",
            "Train Loss: 0.269640743732\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16300 iterations: 75.0142370661 mins\n",
            "Train Loss: 0.139272809029\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16400 iterations: 75.475132966 mins\n",
            "Train Loss: 0.155123859644\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16500 iterations: 75.9361726522 mins\n",
            "Train Loss: 0.18193423748\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16600 iterations: 76.3970152179 mins\n",
            "Train Loss: 0.406371384859\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 87.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16700 iterations: 76.8609753331 mins\n",
            "Train Loss: 0.140808910131\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16800 iterations: 77.3249895334 mins\n",
            "Train Loss: 0.345684289932\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16900 iterations: 77.7892308672 mins\n",
            "Train Loss: 0.272883176804\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17000 iterations: 78.2530228178 mins\n",
            "Train Loss: 0.228395760059\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 85.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17100 iterations: 78.7174628178 mins\n",
            "Train Loss: 0.191442415118\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17200 iterations: 79.1816427509 mins\n",
            "Train Loss: 0.14853194356\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17300 iterations: 79.6455284357 mins\n",
            "Train Loss: 0.204766780138\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17400 iterations: 80.1096941352 mins\n",
            "Train Loss: 0.209900200367\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17500 iterations: 80.5730139494 mins\n",
            "Train Loss: 0.18358194828\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17600 iterations: 81.0367930333 mins\n",
            "Train Loss: 0.279353797436\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17700 iterations: 81.5004400174 mins\n",
            "Train Loss: 0.181034892797\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17800 iterations: 81.9646050493 mins\n",
            "Train Loss: 0.177338212729\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17900 iterations: 82.4286708355 mins\n",
            "Train Loss: 0.261421740055\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18000 iterations: 82.893221434 mins\n",
            "Train Loss: 0.32588249445\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18100 iterations: 83.3571005662 mins\n",
            "Train Loss: 0.230239629745\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18200 iterations: 83.8214308023 mins\n",
            "Train Loss: 0.228214278817\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18300 iterations: 84.2862496177 mins\n",
            "Train Loss: 0.143357723951\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18400 iterations: 84.7504410187 mins\n",
            "Train Loss: 0.168090507388\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18500 iterations: 85.2144602338 mins\n",
            "Train Loss: 0.146981909871\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 85.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18600 iterations: 85.6788478653 mins\n",
            "Train Loss: 0.205168545246\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18700 iterations: 86.1433972994 mins\n",
            "Train Loss: 0.148359566927\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18800 iterations: 86.6079587022 mins\n",
            "Train Loss: 0.140291005373\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18900 iterations: 87.0723885179 mins\n",
            "Train Loss: 0.192262530327\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19000 iterations: 87.5362543186 mins\n",
            "Train Loss: 0.197763547301\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19100 iterations: 88.0005559683 mins\n",
            "Train Loss: 0.160756886005\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19200 iterations: 88.4645129005 mins\n",
            "Train Loss: 0.215505585074\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 87.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19300 iterations: 88.9284018834 mins\n",
            "Train Loss: 0.17205157876\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19400 iterations: 89.3924670021 mins\n",
            "Train Loss: 0.165663599968\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19500 iterations: 89.8562269489 mins\n",
            "Train Loss: 0.148255214095\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19600 iterations: 90.3201526841 mins\n",
            "Train Loss: 0.261656880379\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19700 iterations: 90.7838518341 mins\n",
            "Train Loss: 0.162424966693\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19800 iterations: 91.2484476686 mins\n",
            "Train Loss: 0.141618683934\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19900 iterations: 91.7125613173 mins\n",
            "Train Loss: 0.138907566667\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 85.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 20000 iterations: 92.1766770323 mins\n",
            "Train Loss: 0.19880604744\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I4pZ6Ft1yErv",
        "colab_type": "code",
        "outputId": "0169e5f9-8098-4385-8327-5882f435e0a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "cell_type": "code",
      "source": [
        "cat1 = 121\n",
        "char1 = 1\n",
        "ex1 = np.random.randint(20)\n",
        "cat2 = 121\n",
        "char2 = 5\n",
        "ex2 = np.random.randint(20)\n",
        "h = w = 105\n",
        "example1 = X_test[cat1,char1,:,:].reshape(1,h,w,1)\n",
        "example2 = X_test[cat2,char2,:,:].reshape(1,h,w,1)\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(example1.reshape(105,105), cmap = 'gray')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(example2.reshape(105,105), cmap = 'gray')\n",
        "model.predict([example1, example2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99068743]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAADtCAYAAABu1gaFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDHwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "mAOdXDdjLWKm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}