{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinavj98/machine-learning/blob/master/gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yz1KDNMGTvr",
        "colab_type": "code",
        "outputId": "9ab1b793-ab01-484e-eeb1-c81fb5b27735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU6M3kndXjTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from random import randint\n",
        "import  os\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQuc4MSAXuf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3KeJ8-WaTqr",
        "colab_type": "code",
        "outputId": "cda9cddc-bd52-4f51-ba5a-b0ac98ee5801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Train Images:\", train_images.shape, \"Test Images:\", test_images.shape)\n",
        "label_text = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Images: (60000, 28, 28) Test Images: (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RxGJQNWZk0p",
        "colab_type": "code",
        "outputId": "5d39cc3e-893b-4ef6-a57e-24ee1539666e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "for i in range(10):\n",
        "  j = randint(0,60000)\n",
        "  plt.subplot(2,5,i+1)\n",
        "  plt.title(label_text[train_labels[j]])\n",
        "  plt.imshow(train_images[j], cmap = 'gray')\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADfCAYAAADmzyjKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nV+iO4zgxwSt0x3GcmPD/ARCCeSD/JBNWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asheEAyuolwL",
        "colab_type": "code",
        "outputId": "390438bb-a2dd-4ab7-d2b9-537661e8295a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_images = train_images.astype('float32')\n",
        "test_images = test_images.astype('float32')\n",
        "train_images = train_images/255.0\n",
        "test_images = test_images/255.0\n",
        "print(train_images[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333336\n",
            "  0.6862745  0.10196079 0.6509804  1.         0.96862745 0.49803922\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
            "  0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            "  0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.19215687 0.93333334 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.9843137\n",
            "  0.3647059  0.32156864 0.32156864 0.21960784 0.15294118 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.07058824 0.85882354 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.99215686 0.7764706  0.7137255  0.96862745 0.94509804\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
            "  0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.05490196 0.00392157 0.6039216\n",
            "  0.99215686 0.3529412  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.54509807\n",
            "  0.99215686 0.74509805 0.00784314 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.04313726\n",
            "  0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.13725491 0.94509804 0.88235295 0.627451   0.42352942 0.00392157\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.31764707 0.9411765  0.99215686 0.99215686 0.46666667\n",
            "  0.09803922 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
            "  0.5882353  0.10588235 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.0627451  0.3647059  0.9882353\n",
            "  0.99215686 0.73333335 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.9764706\n",
            "  0.99215686 0.9764706  0.2509804  0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
            "  0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.15294118 0.5803922  0.8980392  0.99215686 0.99215686 0.99215686\n",
            "  0.98039216 0.7137255  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.09411765 0.44705883\n",
            "  0.8666667  0.99215686 0.99215686 0.99215686 0.99215686 0.7882353\n",
            "  0.30588236 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.07058824 0.67058825 0.85882354 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.7647059  0.3137255  0.03529412 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.21568628 0.6745098\n",
            "  0.8862745  0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
            "  0.52156866 0.04313726 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.53333336 0.99215686\n",
            "  0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9Mzwp23aCtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GAN:\n",
        "  def make_model(self):\n",
        "    self.gen = self.generator()\n",
        "    self.dis = self.discriminator()\n",
        "        \n",
        "  def run_generator(self, z, is_training):\n",
        "    x = self.gen['dense1'](z)\n",
        "    x = self.gen['dropout1'](x, is_training)\n",
        "    x = self.gen['bnorm1'](x, is_training)\n",
        "    x = tf.reshape(x, (-1,7,7,1))\n",
        "    x = self.gen['convt1'](x)\n",
        "    x = self.gen['dropout2'](x, is_training)\n",
        "    x = self.gen['bnorm2'](x, is_training)\n",
        "    output = self.gen['convt2'](x)\n",
        "#     x = self.gen['dropout3'](x, is_training)\n",
        "#     x = self.gen['bnorm3'](x, is_training)\n",
        "#     x = self.gen['convt3'](x)\n",
        "#     x = self.gen['dropout4'](x, is_training)\n",
        "#     x = self.gen['bnorm4'](x, is_training)\n",
        "#     output = self.gen['convt4'](x)\n",
        "    return output\n",
        "  \n",
        "  def run_discriminator(self, z):\n",
        "    x = self.dis['conv1'](z)\n",
        "    x = self.dis['dropout1'](x)\n",
        "    x = self.dis['conv2'](x)\n",
        "    x = self.dis['dropout2'](x)\n",
        "    x = self.dis['conv3'](x)\n",
        "    x = self.dis['dropout3'](x)\n",
        "    x = self.dis['flatten'](x)\n",
        "    logits = self.dis['dense1'](x)\n",
        "    output = self.dis['logits'](x)\n",
        "    return logits, output\n",
        "  \n",
        "  def generator(self):\n",
        "    layers = {}\n",
        "    keep_prob = 0.3\n",
        "    momentum = 0.99\n",
        "    nodes = 7 * 7\n",
        "    layers['dense1'] = tf.keras.layers.Dense(units=nodes, activation=tf.nn.leaky_relu, name = 'gen/dense1')\n",
        "    layers['dropout1'] = tf.keras.layers.Dropout(keep_prob, name = 'gen/dropout1')      \n",
        "    layers['bnorm1'] = tf.keras.layers.BatchNormalization(momentum = momentum, name = 'gen/bnorm1')  \n",
        "    layers['convt1'] = tf.keras.layers.Conv2DTranspose(kernel_size=5, filters=64, strides=2, padding='same', activation=tf.nn.leaky_relu, name = 'gen/convt1')\n",
        "    layers['dropout2'] = tf.keras.layers.Dropout(keep_prob, name = 'gen/dropout2')\n",
        "    layers['bnorm2'] = tf.keras.layers.BatchNormalization(momentum=momentum, name = 'gen/bnorm2')\n",
        "    layers['convt2'] = tf.layers.Conv2DTranspose(kernel_size=5, filters=1, strides=2, padding='same', activation=tf.nn.sigmoid, name = 'gen/convt2')\n",
        "#     layers['dropout3'] = tf.keras.layers.Dropout(keep_prob, name = 'gen/dropout3')\n",
        "#     layers['bnorm3'] = tf.keras.layers.BatchNormalization(momentum=momentum, name = 'gen/bnorm3')\n",
        "#     layers['convt3'] = tf.keras.layers.Conv2DTranspose(kernel_size=5, filters=64, strides=1, padding='same', activation=tf.nn.leaky_relu, name = 'gen/convt3')\n",
        "#     layers['dropout4'] = tf.keras.layers.Dropout(keep_prob, name = 'gen/dropout4')\n",
        "#     layers['bnorm4'] = tf.keras.layers.BatchNormalization(momentum=momentum, name = 'gen/bnorm4')\n",
        "#     layers['convt4'] = tf.keras.layers.Conv2DTranspose(kernel_size=5, filters=1, strides=1, padding='same', activation=tf.nn.sigmoid, name = 'gen/convt4')\n",
        "\n",
        "    return layers\n",
        "\n",
        "  def discriminator(self):\n",
        "    layers = {}\n",
        "    keep_prob = 0.5\n",
        "    layers['conv1'] = tf.keras.layers.Conv2D(kernel_size=5, filters=64, strides=2, padding='same', activation=tf.nn.leaky_relu, input_shape = (28,28,1), name = 'dis/conv1')\n",
        "    layers['dropout1'] = tf.keras.layers.Dropout(keep_prob, name = 'dis/dropout1')\n",
        "    layers['conv2'] = tf.keras.layers.Conv2D(kernel_size=5, filters=64, strides=1, padding='same', activation=tf.nn.leaky_relu, name = 'dis/conv2')\n",
        "    layers['dropout2'] = tf.keras.layers.Dropout(keep_prob,name = 'dis/dropout2')\n",
        "    layers['conv3'] = tf.keras.layers.Conv2D(kernel_size=5, filters=64, strides=1, padding='same', activation=tf.nn.leaky_relu, name = 'dis/conv3')\n",
        "    layers['dropout3'] = tf.keras.layers.Dropout(keep_prob, name = 'dis/dropout3')\n",
        "    layers['flatten'] = tf.keras.layers.Flatten(name = 'dis/flatten')\n",
        "    layers['dense1']=tf.keras.layers.Dense(units=128,activation=tf.nn.leaky_relu, name = 'dis/dense1')\n",
        "    layers['logits']=tf.keras.layers.Dense(units=1, activation = tf.nn.sigmoid, name = 'dis/logits')\n",
        "\n",
        "    return layers\n",
        "  \n",
        "#   def train_step_generator(self):\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqrBUYKbzPKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_func(logits_in,labels_in):\n",
        "  return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in,labels=labels_in))\n",
        "  \n",
        "  \n",
        "def generate_fakes(n):\n",
        "  x = np.random.rand(n,28*28)\n",
        "  x = x*2-1\n",
        "  return x\n",
        "\n",
        "\n",
        "def dis_accuracy(D_logits, thresh, pos):\n",
        "  D_logits = D_logits.reshape(-1)\n",
        "  if not pos:\n",
        "    return len(D_logits[np.where(D_logits < thresh)])/len(D_logits)\n",
        "  else:\n",
        "    return len(D_logits[np.where(D_logits > thresh)])/len(D_logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdWvyq0Pe1QW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.get_default_graph()\n",
        "tf.reset_default_graph()\n",
        "fashion_GAN = GAN()\n",
        "fashion_GAN.make_model()\n",
        "\n",
        "\n",
        "# D_logits_fake= fashion_GAN.run_discriminator(fake_images)\n",
        "# D_logits_real= fashion_GAN.run_discriminator(real_images)\n",
        "# D_real_loss=loss_func(D_logits_real, tf.ones_like(D_logits_real)*0.9) #Smoothing for generalization\n",
        "# D_fake_loss=loss_func(D_logits_fake, tf.zeros_like(D_logits_fake))\n",
        "# D_loss=D_real_loss+D_fake_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D-Xkz3d5cCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "real_images=tf.placeholder(tf.float32,shape=[None,28, 28, 1])\n",
        "# fake_images=tf.placeholder(tf.float32,shape=[None,28, 28, 1])\n",
        "z=tf.placeholder(tf.float32,shape=[None,100])\n",
        "\n",
        "G = fashion_GAN.run_generator(z, True)\n",
        "D_logits_real, D_output_real = fashion_GAN.run_discriminator(real_images)\n",
        "D_logits_fake, D_output_fake = fashion_GAN.run_discriminator(G)\n",
        "D_real_loss = loss_func(D_logits_real, tf.ones_like(D_logits_real)*0.9) #Smoothing for generalization\n",
        "D_fake_loss = loss_func(D_logits_fake, tf.zeros_like(D_logits_fake)+0.1)\n",
        "D_loss = (D_real_loss + D_fake_loss)/2\n",
        "G_loss = loss_func(D_logits_fake,tf.ones_like(D_logits_fake))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_qlohHMbLEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "samples=[] #generator examples\n",
        "D_losses = []\n",
        "G_losses = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXiG6PXlTav9",
        "colab_type": "code",
        "outputId": "e170ce6c-d936-47e5-beec-497ba458f4a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "lr_D=0.0002\n",
        "lr_G=0.0002\n",
        "batch_size = 128\n",
        "#Do this when multiple networks interact with each other\n",
        "tvars=tf.trainable_variables()  #returns all variables created(the two variable scopes) and makes trainable true\n",
        "d_vars=[var for var in tvars if 'dis' in var.name]\n",
        "g_vars=[var for var in tvars if 'gen' in var.name]\n",
        "\n",
        "D_trainer=tf.train.AdamOptimizer(lr_D, 0.5).minimize(D_loss,var_list=d_vars)\n",
        "G_trainer=tf.train.AdamOptimizer(lr_G, 0.5).minimize(G_loss,var_list=g_vars)\n",
        "epochs=1000\n",
        "init=tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "print(d_vars, g_vars)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'dis/conv1/kernel:0' shape=(5, 5, 1, 64) dtype=float32>, <tf.Variable 'dis/conv1/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'dis/conv2/kernel:0' shape=(5, 5, 64, 64) dtype=float32>, <tf.Variable 'dis/conv2/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'dis/conv3/kernel:0' shape=(5, 5, 64, 64) dtype=float32>, <tf.Variable 'dis/conv3/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'dis/dense1/kernel:0' shape=(12544, 128) dtype=float32>, <tf.Variable 'dis/dense1/bias:0' shape=(128,) dtype=float32>, <tf.Variable 'dis/logits/kernel:0' shape=(12544, 1) dtype=float32>, <tf.Variable 'dis/logits/bias:0' shape=(1,) dtype=float32>] [<tf.Variable 'gen/dense1/kernel:0' shape=(100, 49) dtype=float32>, <tf.Variable 'gen/dense1/bias:0' shape=(49,) dtype=float32>, <tf.Variable 'gen/bnorm1/gamma:0' shape=(49,) dtype=float32>, <tf.Variable 'gen/bnorm1/beta:0' shape=(49,) dtype=float32>, <tf.Variable 'gen/convt1/kernel:0' shape=(5, 5, 64, 1) dtype=float32>, <tf.Variable 'gen/convt1/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'gen/bnorm2/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'gen/bnorm2/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'gen/convt2/kernel:0' shape=(5, 5, 1, 64) dtype=float32_ref>, <tf.Variable 'gen/convt2/bias:0' shape=(1,) dtype=float32_ref>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYLGOWQC7Ng9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  l = False\n",
        "  sess.run(init)\n",
        "  restore = False\n",
        "  num_batches = train_images.shape[0]//batch_size\n",
        "  if restore:\n",
        "    if os.path.exists(\"/content/drive/My Drive/checkpoint\"):\n",
        "      saver.restore(sess, \"/content/drive/My Drive/checkpt.ckpt\")\n",
        "      print(\"Restored model\")\n",
        " \n",
        "    \n",
        "  for epoch in range(epochs):\n",
        "    for i in range(num_batches):\n",
        "      batch = train_images[batch_size*i:(batch_size)*(i+1)]\n",
        "      batch_images = batch*2-1\n",
        "      batch_images = np.reshape(batch_images, (-1,28,28,1))\n",
        "      batch_z = np.random.uniform(-1,1,size=(batch_size,100))\n",
        "      sess.run(D_trainer, feed_dict = {real_images:batch_images,z:batch_z})\n",
        "      for l in range(500):\n",
        "        batch_z = np.random.uniform(-1,1,size=(batch_size,100))\n",
        "        sess.run(G_trainer, feed_dict={z:batch_z})\n",
        "      \n",
        "    print(\"on epoch{}\".format(epoch))\n",
        "    \n",
        "    if epoch%10 == 0:\n",
        "      print(\"Saving\")\n",
        "      save_path = saver.save(sess, \"/content/drive/My Drive/checkpt.ckpt\")\n",
        "      batch_z = np.random.uniform(-1,1,size=(10000,100))\n",
        "      sample_z=np.random.uniform(-1,1,size=(9,100))\n",
        "      gen_sample=sess.run(G,feed_dict={z:sample_z})\n",
        "      print(sample_z)\n",
        "      for k in range(9):\n",
        "        plt.subplot(3,3,k+1)\n",
        "        plt.imshow((gen_sample[k].reshape(28,28)+1)/2, cmap = 'gray')\n",
        "      plt.show()\n",
        "      D_real, D_fake, lossD, lossG = sess.run([D_logits_real, D_logits_fake, D_loss, G_loss], feed_dict={real_images:np.reshape(test_images*2-1, (-1,28,28,1)), z:batch_z})\n",
        "      D_acc_real = dis_accuracy(np.array(D_real), 0.5, True) \n",
        "      D_acc_fake = dis_accuracy(np.array(D_fake), 0.5, False)\n",
        "      G_acc = dis_accuracy(np.array(D_fake), 0.5, True)\n",
        "\n",
        "      print(\"lossD: {}, lossG: {}, accG: {}, accD: {}\".format(lossD, lossG, G_acc, (D_acc_real + D_acc_fake)/2))\n",
        "      samples.append(gen_sample)\n",
        "      D_losses.append(lossD)\n",
        "      G_losses.append(lossG)\n",
        "\n",
        "   \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkLBrn5-EKFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  restore = True\n",
        "  if restore:\n",
        "    if os.path.exists(\"/content/drive/My Drive/checkpoint\"):\n",
        "      saver.restore(sess, \"/content/drive/My Drive/checkpt.ckpt\")\n",
        "      print(\"Restored model\")\n",
        "    sample_z = np.random.uniform(-1,1,(10,100))\n",
        "    gen_sample=sess.run(fashion_GAN.run_generator(z, False),feed_dict={z:sample_z})\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ1LveN6EmFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_sample[1][:,:].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyw-fP9fEZc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(11):\n",
        "  plt.subplot(2,6,i+1)\n",
        "  plt.imshow(((gen_sample[i, :, :])))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xraGm5WTTuFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(epochs):\n",
        "    if epoch%100 == 0:\n",
        "      print(\"Saving\")\n",
        "#       save_path = saver.save(sess, \"/content/drive/My Drive/checkpt.ckpt\")\n",
        "      num_batches=train_images.shape[0]//batch_size\n",
        "    if epoch%5 == 0:\n",
        "        logits_fake = sess.run([D_logits_fake], feed_dict = {fake_images : np.random.uniform(-1,1,size=(train_images.shape[0],28,28,1))})\n",
        "        logits_real = sess.run([D_logits_real], feed_dict = {real_images : train_images.reshape(-1,28,28,1)})\n",
        "        print(\"Epoch : {}, Loss_fake : {}, Loss_real: {}\".format(epoch, dis_accuracy(np.array(logits_fake), 0.5, False), dis_accuracy(np.array(logits_real), 0.5, True)))\n",
        "    for i in range(num_batches):\n",
        "      batch = train_images[batch_size*i:(batch_size)*(i+1)]\n",
        "      batch_images = batch.reshape((batch_size,28,28,1))\n",
        "      batch_images = batch_images*2-1\n",
        "      batch_fake = np.random.uniform(-1,1,size=(batch_size,28,28,1))\n",
        "      lossD, _=sess.run([D_loss, D_trainer],feed_dict={real_images:batch_images,fake_images:batch_fake})\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6IAcf7sOLWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(samples[68].reshape(28,28))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKJlO0B_ALic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "examples = []\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for i in range(100):\n",
        "      sample_z=np.random.uniform(-1,1,size=(1,100))\n",
        "      gen_sample=sess.run(fashion_GAN.run_generator(z),feed_dict={z:sample_z})\n",
        "      examples.append(gen_sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRVbmqedTdlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(11):\n",
        "  plt.subplot(2,6,i+1)\n",
        "  plt.imshow((samples[i].reshape(28,28)+1)/2, cmap = 'gray')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCjblcz-lBTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivfdeP-sc4rF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tf.trainable_variables())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ed2wIZtdghe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  a = sess.run(G, feed_dict = {z : np.random.uniform(-1,1,size=(1,100))})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w005LbcTrD28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}